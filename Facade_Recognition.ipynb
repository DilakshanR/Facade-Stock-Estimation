{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2qXfzOVlFe2"
      },
      "outputs": [],
      "source": [
        "#Removed imbalanced classes\n",
        "UNIDENTIFIED_CLASS_TO_REMOVE = 1500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VF0vCoF1LZaJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNomFc5jvHF-"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLGRLJSkBcBV"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries and modules for deep learning using PyTorch, data manipulation, and visualization.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tempfile import TemporaryDirectory\n",
        "from torch.utils.data import Dataset, SubsetRandomSampler\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "cudnn.benchmark = True\n",
        "plt.ion()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZkvjiMmE1lr"
      },
      "outputs": [],
      "source": [
        "tl_class_dict = {\n",
        " 0: \"Face Brick\",\n",
        " 1: \"Timber\",\n",
        " 2: \"Steel Sheet\",\n",
        " 3: \"Plastered and Painted\",\n",
        " 4: \"Concrete and Glass\",\n",
        " 5: \"Glass\",\n",
        " 6: \"Fiber Cement Sheet\",\n",
        " 7: \"Concrete Panels\",\n",
        " 8: \"Unidentified\"\n",
        "}\n",
        "tl_class_inv_map = {v:k for k,v in tl_class_dict.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nfY4NYA101N"
      },
      "outputs": [],
      "source": [
        "# Implementation of a custom dataset class for processing and managing street view image data.\n",
        "class StreetViewImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_dir, split_ratio=0.8, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.split_ratio = split_ratio\n",
        "        self.transform = transform\n",
        "        self.classes = sorted(os.listdir(root_dir))\n",
        "        self.class_to_idx = tl_class_inv_map\n",
        "        self.data = self._load_data()\n",
        "        self._analyze_data()\n",
        "        self._split_data()\n",
        "\n",
        "    def _analyze_data(self):\n",
        "        label_counter = Counter({label: 0 for label in range(0, 9)})\n",
        "\n",
        "        # Count the occurrences of each label in the data\n",
        "        for _, label in self.data:\n",
        "            if label in range(0,9):\n",
        "                label_counter[label] += 1\n",
        "\n",
        "        # Display the counts for each label\n",
        "        for label, count in label_counter.items():\n",
        "            print(f\"{label}: {100*count / self.__len__():.3f}% \\t {count} \\t\\t {tl_class_dict[label]}\")\n",
        "\n",
        "    def _load_data(self):\n",
        "        other_drop_count = 0\n",
        "        folders = ['Commercial and business Zone', 'Mixed use zone',\n",
        "                 'Industrial and utilities Zone',  'Residential Zone', 'Glass (Newly added)']\n",
        "        data = []\n",
        "        valid_extensions = ['jpg', 'jpeg', 'png', 'bmp']\n",
        "        for folder in folders:\n",
        "            dir = os.path.join(self.root_dir, folder)\n",
        "            subfolders = os.listdir(dir)\n",
        "            labels = [f for f in subfolders if f.endswith(\".csv\")]\n",
        "            for label in labels:\n",
        "                subdir = label[:-4]\n",
        "                if subdir == \"Residential less than 3.5 height\":\n",
        "                    label_file = pd.read_csv(os.path.join(dir, label),\n",
        "                                             usecols = ['OBJECTID *', \"Type\"])\n",
        "                    label_file = label_file.rename({\"Type\": \"Typology\"}, axis='columns')\n",
        "                else:\n",
        "                    label_file = pd.read_csv(os.path.join(dir, label),\n",
        "                                         usecols = ['OBJECTID *', \"Typology\"])\n",
        "                label_file.set_index('OBJECTID *', inplace=True)\n",
        "                label_file.dropna(inplace=True) # drop images without label\n",
        "                images = os.listdir(os.path.join(dir, subdir))\n",
        "                for im in images:\n",
        "                    try:\n",
        "                        im_path = os.path.join(dir, subdir, im)\n",
        "                        im_id = int(im.split('_')[0])\n",
        "                        if im_id in label_file.index:  # Check if im_id exists in the index\n",
        "                            label = label_file.loc[im_id, \"Typology\"]\n",
        "                            label = tl_class_inv_map.get(label, 8)\n",
        "                            if label == 8 and (other_drop_count < UNIDENTIFIED_CLASS_TO_REMOVE):\n",
        "                                other_drop_count += 1\n",
        "                                continue\n",
        "                            img_extension = im_path.split('.')[-1].lower()\n",
        "                            if img_extension in valid_extensions:\n",
        "                                data.append((im_path, label))\n",
        "                    except Exception as e:\n",
        "                        print(e)\n",
        "        return data\n",
        "\n",
        "    def _split_data(self):\n",
        "        \"\"\"split the dataset train, test set\"\"\"\n",
        "        dataset_size = len(self.data)\n",
        "        split_idx = int(dataset_size * self.split_ratio)\n",
        "        indices = list(range(dataset_size))\n",
        "        # Shuffle the indices before splitting\n",
        "        torch.manual_seed(42)  # For reproducibility\n",
        "        shuffled_indices = torch.randperm(dataset_size)\n",
        "\n",
        "        self.train_indices = shuffled_indices[:split_idx]\n",
        "        self.test_indices = shuffled_indices[split_idx:]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.data[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def get_train_sampler(self):\n",
        "        return SubsetRandomSampler(self.train_indices)\n",
        "\n",
        "    def get_test_sampler(self):\n",
        "        return SubsetRandomSampler(self.test_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbTs77IoQlx6"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE=16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6Di6GC6t_tP"
      },
      "outputs": [],
      "source": [
        "#Data transformation\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "tl_dataset = StreetViewImageDataset(\"/content/drive/MyDrive/StreetViewImages\",\n",
        "                                  split_ratio=0.8, transform=data_transforms)\n",
        "# print(tl_dataset)\n",
        "dataloaders = {'train': torch.utils.data.DataLoader(tl_dataset, batch_size=BATCH_SIZE,\n",
        "                                              num_workers=4,\n",
        "                                             sampler=tl_dataset.get_train_sampler(),\n",
        "                                                    prefetch_factor=4),\n",
        "              'test': torch.utils.data.DataLoader(tl_dataset, batch_size=BATCH_SIZE,\n",
        "                                              num_workers=4,\n",
        "                                             sampler=tl_dataset.get_test_sampler(),\n",
        "                                                 prefetch_factor=4)}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqSTX5tTXNzO"
      },
      "outputs": [],
      "source": [
        "tl_dataset.__len__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5rXxwu2C0bd"
      },
      "outputs": [],
      "source": [
        "# Visualizing a batch of images from a training dataset using PyTorch utilities.\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Display image for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYDMq0UmC48Z"
      },
      "outputs": [],
      "source": [
        "#Model Training\n",
        "def train_model(dir, model, criterion, optimizer, scheduler, num_epochs=25, load=False):\n",
        "    since = time.time()\n",
        "    best_model_params_path = os.path.join(dir, 'best_model_params.pt')\n",
        "    if load:\n",
        "        model.load_state_dict(torch.load(best_model_params_path))\n",
        "    best_acc = 0.0\n",
        "    training_data = []\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "        # Each epoch has a training and test phase\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode: regularization active\n",
        "            elif phase == 'test' and epoch % 5 == 0:\n",
        "                model.eval()   # Set model to evaluate mode: regularization disabled\n",
        "            else:\n",
        "                continue\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in tqdm(dataloaders[phase]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs) # forward pass\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                epoch_loss = running_loss / tl_dataset.get_train_sampler().__len__()\n",
        "                epoch_acc = running_corrects.double() / tl_dataset.get_train_sampler().__len__()\n",
        "            if phase == 'test':\n",
        "                epoch_loss = running_loss / tl_dataset.get_test_sampler().__len__()\n",
        "                epoch_acc = running_corrects.double() / tl_dataset.get_test_sampler().__len__()\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "            training_data.append((epoch, phase, epoch_loss, epoch_acc))\n",
        "            # deep copy the model\n",
        "            if phase == 'test' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                torch.save(model.state_dict(), best_model_params_path)\n",
        "        print()\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best test Acc: {best_acc:4f}')\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(torch.load(best_model_params_path))\n",
        "    return model, training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlr-BfM7C5Dk"
      },
      "outputs": [],
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title(f'predicted: {tl_class_dict[preds[j]]}')\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2g8HZTYC5GS"
      },
      "outputs": [],
      "source": [
        "# Configuring the ResNet-50 model for classification with custom output layer, loss function, optimizer, and learning rate scheduler.\n",
        "model_ft = models.resnet50(weights='IMAGENET1K_V1') #Other ResNET and DenseNET family architecture also tested\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.\n",
        "model_ft.fc = nn.Linear(num_ftrs, len(tl_class_dict))\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Given class frequencies\n",
        "class_counts = torch.tensor([3250, 1523, 638, 2748, 182, 173, 146, 396, 1653])\n",
        "\n",
        "# Total number of samples\n",
        "total_samples = class_counts.sum().item()\n",
        "\n",
        "# Calculate weights: Number of samples divided by (number of classes * class counts)\n",
        "weights = total_samples / (len(class_counts) * class_counts)\n",
        "\n",
        "# Normalize weights to make the smallest weight 1 for better stability in training\n",
        "weights = weights / weights.min()\n",
        "\n",
        "# Example weights (you should calculate these based on your specific class distribution)\n",
        "class_weights = weights.to(device)\n",
        "\n",
        "# Initialize the weighted CrossEntropyLoss\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNFfI5VuC5JB"
      },
      "outputs": [],
      "source": [
        "model_dir = \"/content/drive/MyDrive/StreetViewImages/10jul\"\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAV9uDrURP6Z"
      },
      "outputs": [],
      "source": [
        "model_ft, training_data = train_model(model_dir, model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                                      num_epochs=50, load=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OK_dUr01_Nx2"
      },
      "outputs": [],
      "source": [
        "# Plotting training and testing loss and accuracy over epochs to visualize model performance.\n",
        "epoch, train_acc, test_acc, train_loss, test_loss = [], [] , [], [], []\n",
        "test_epoch = []\n",
        "for e, data in enumerate(training_data):\n",
        "    ep, phase, epoch_loss, epoch_acc = data\n",
        "    if phase == 'train':\n",
        "        train_acc.append(epoch_acc.cpu())\n",
        "        train_loss.append(epoch_loss)\n",
        "        epoch.append(ep)\n",
        "    elif phase == \"test\":\n",
        "        test_acc.append(epoch_acc.cpu())\n",
        "        test_loss.append(epoch_loss)\n",
        "        test_epoch.append(ep)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(20,5))\n",
        "fig.suptitle(\"Training Curves\", fontsize=16)\n",
        "ax[0].plot(epoch, train_loss, label='Train loss')\n",
        "ax[0].plot(test_epoch, test_loss, label=\"Test loss\")\n",
        "ax[0].legend()\n",
        "ax[0].grid()\n",
        "ax[1].plot(epoch, train_acc, label='Train accuracy')\n",
        "ax[1].plot(test_epoch, test_acc, label='Test accuracy')\n",
        "ax[1].legend()\n",
        "ax[1].grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXBugHZNSKjb"
      },
      "outputs": [],
      "source": [
        "#Saving model\n",
        "torch.save(model_ft.state_dict(), model_dir + \"/resnet50.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "from matplotlib.patches import Rectangle\n",
        "import matplotlib.font_manager as fm\n",
        "from pandas import DataFrame\n",
        "from string import ascii_uppercase\n",
        "from matplotlib.collections import QuadMesh\n",
        "\n",
        "\n",
        "def get_new_fig(fn, figsize=[9, 9]):\n",
        "\n",
        "    fig1 = plt.figure(fn, figsize)\n",
        "    ax1 = fig1.gca()  # Get Current Axis\n",
        "    ax1.cla()  # clear existing plot\n",
        "    return fig1, ax1\n",
        "\n",
        "def configcell_text_and_colors(array_df, lin, col, oText, facecolors, posi, fz,\n",
        "                               fmt, show_null_values=0):\n",
        "    text_add = [];\n",
        "    text_del = [];\n",
        "    cell_val = array_df[lin][col]\n",
        "    sel_col = array_df[-1][col]\n",
        "    tot_all = array_df[-1][-1]\n",
        "    per = (float(cell_val) / sel_col) * 100\n",
        "    curr_column = array_df[:, col]\n",
        "    ccl = len(curr_column)\n",
        "\n",
        "    # last line  and/or last column\n",
        "    if (col == (ccl - 1)) or (lin == (ccl - 1)):\n",
        "        # tots and percents\n",
        "        if (cell_val != 0):\n",
        "            if (col == ccl - 1) and (lin == ccl - 1):\n",
        "                tot_rig = 0\n",
        "                for i in range(array_df.shape[0] - 1):\n",
        "                    tot_rig += array_df[i][i]\n",
        "                per_ok = (float(tot_rig) / cell_val) * 100\n",
        "            elif (col == ccl - 1):\n",
        "                tot_rig = array_df[lin][lin]\n",
        "                per_ok = (float(tot_rig) / cell_val) * 100\n",
        "            elif (lin == ccl - 1):\n",
        "                tot_rig = array_df[col][col]\n",
        "                per_ok = (float(tot_rig) / cell_val) * 100\n",
        "            per_err = 100 - per_ok\n",
        "        else:\n",
        "            per_ok = per_err = 0\n",
        "\n",
        "        per_ok_s = ['%.2f%%' % (per_ok), '100%'][per_ok == 100]\n",
        "\n",
        "        # text to DEL\n",
        "        text_del.append(oText)\n",
        "\n",
        "        # text to ADD\n",
        "        font_prop = fm.FontProperties(weight='bold', size=fz)\n",
        "        text_kwargs = dict(color='w', ha=\"center\", va=\"center\", gid='sum',\n",
        "                           fontproperties=font_prop)\n",
        "        lis_txt = ['%d' % (cell_val), per_ok_s]\n",
        "        lis_kwa = [text_kwargs]\n",
        "        dic = text_kwargs.copy();\n",
        "        dic['color'] = 'g';\n",
        "        lis_kwa.append(dic);\n",
        "        dic = text_kwargs.copy();\n",
        "        dic['color'] = 'r';\n",
        "        lis_kwa.append(dic);\n",
        "        lis_pos = [(oText._x, oText._y - 0.3), (oText._x, oText._y),\n",
        "                   (oText._x, oText._y + 0.3)]\n",
        "        for i in range(len(lis_txt)):\n",
        "            newText = dict(x=lis_pos[i][0], y=lis_pos[i][1], text=lis_txt[i],\n",
        "                           kw=lis_kwa[i])\n",
        "            text_add.append(newText)\n",
        "\n",
        "        # set background color for sum cells (last line and last column)\n",
        "        carr = [0.0, 0.0, 1.0, 1.0]\n",
        "        if (col == ccl - 1) and (lin == ccl - 1):\n",
        "            carr = [0.0, 0.0, 1.0, 1.0]\n",
        "        facecolors[posi] = carr\n",
        "\n",
        "    else:\n",
        "        if (per > 0):\n",
        "            txt = '%s\\n%.2f%%' % (cell_val, per)\n",
        "        else:\n",
        "            if (show_null_values == 0):\n",
        "                txt = ''\n",
        "            elif (show_null_values == 1):\n",
        "                txt = '0'\n",
        "            else:\n",
        "                txt = '0\\n0.0%'\n",
        "        oText.set_text(txt)\n",
        "\n",
        "        # main diagonal\n",
        "        if (col == lin):\n",
        "            # set color of the textin the diagonal to white\n",
        "            oText.set_color('r')\n",
        "            # set background color in the diagonal to blue\n",
        "            facecolors[posi] = [0.0, 0.0, 1.0, 1.0]\n",
        "        else:\n",
        "            oText.set_color('r')\n",
        "            facecolors[posi] = [0.0, 0.0, 1.0, 1.0]\n",
        "\n",
        "    return text_add, text_del\n",
        "\n",
        "\n",
        "def insert_totals(df_cm):\n",
        "    sum_col = []\n",
        "    for c in df_cm.columns:\n",
        "        sum_col.append(df_cm[c].sum())\n",
        "    sum_lin = []\n",
        "    for item_line in df_cm.iterrows():\n",
        "        sum_lin.append(item_line[1].sum())\n",
        "    df_cm['sum_lin'] = sum_lin\n",
        "    sum_col.append(np.sum(sum_lin))\n",
        "    df_cm.loc['sum_col'] = sum_col\n",
        "\n",
        "\n",
        "def pretty_plot_confusion_matrix(df_cm, annot=True, cmap=\"Blues\", fmt='.2f',\n",
        "                                 fz=11,\n",
        "                                 lw=0.5, cbar=False, figsize=[8, 8],\n",
        "                                 show_null_values=0, pred_val_axis='y'):\n",
        "\n",
        "    if (pred_val_axis in ('col', 'x')):\n",
        "        xlbl = 'Predicted'\n",
        "        ylbl = 'Actual'\n",
        "    else:\n",
        "        xlbl = 'Actual'\n",
        "        ylbl = 'Predicted'\n",
        "        df_cm = df_cm.T\n",
        "\n",
        "    # create \"Total\" column\n",
        "    insert_totals(df_cm)\n",
        "\n",
        "    # this is for print allways in the same window\n",
        "    fig, ax1 = get_new_fig('Conf matrix default', figsize)\n",
        "    fig.patch.set_facecolor('white')\n",
        "    ax1.set_facecolor('white')\n",
        "\n",
        "    # thanks for seaborn\n",
        "    white_mask = np.ones_like(df_cm)\n",
        "    ax = sn.heatmap(df_cm, annot=annot, annot_kws={\"size\": fz}, linewidths=lw,\n",
        "                    ax=ax1,\n",
        "                    cbar=cbar, cmap=cmap, linecolor='w', fmt=fmt,mask=white_mask)\n",
        "\n",
        "    # set ticklabels rotation\n",
        "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, fontsize=10)\n",
        "    ax.set_yticklabels(ax.get_yticklabels(), rotation=25, fontsize=10)\n",
        "\n",
        "    # face colors list\n",
        "    quadmesh = ax.findobj(QuadMesh)[0]\n",
        "    facecolors = quadmesh.get_facecolors()\n",
        "\n",
        "    # iter in text elements\n",
        "    array_df = np.array(df_cm.to_records(index=False).tolist())\n",
        "    text_add = []\n",
        "    text_del = []\n",
        "    posi = -1  # from left to right, bottom to top.\n",
        "    for t in ax.collections[0].axes.texts:  # ax.texts:\n",
        "        pos = np.array(t.get_position()) - [0.5, 0.5]\n",
        "        lin = int(pos[1])\n",
        "        col = int(pos[0])\n",
        "        posi += 1\n",
        "\n",
        "        # set text\n",
        "        txt_res = configcell_text_and_colors(array_df, lin, col, t, facecolors,\n",
        "                                             posi, fz, fmt, show_null_values)\n",
        "\n",
        "        text_add.extend(txt_res[0])\n",
        "        text_del.extend(txt_res[1])\n",
        "\n",
        "    # remove the old ones\n",
        "    for item in text_del:\n",
        "        item.remove()\n",
        "    # append the new ones\n",
        "    for item in text_add:\n",
        "        ax.text(item['x'], item['y'], item['text'], **item['kw'])\n",
        "\n",
        "    # titles and legends\n",
        "    ax.set_title('Confusion matrix')\n",
        "    ax.set_xlabel(xlbl)\n",
        "    ax.set_ylabel(ylbl)\n",
        "    plt.tight_layout()  # set layout slim\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix_from_data(y_test, predictions, columns=None,\n",
        "                                    annot=True, cmap=\"Oranges\",\n",
        "                                    fmt='.2f', fz=22, lw=0.5, cbar=False,\n",
        "                                    figsize=[8, 8], show_null_values=0,\n",
        "                                    pred_val_axis='lin'):\n",
        "\n",
        "\n",
        "    # data\n",
        "    if (not columns):\n",
        "        # labels axis string:\n",
        "        columns = ['class %s' % (i) for i in\n",
        "                   list(ascii_uppercase)[0:len(np.unique(y_test))]]\n",
        "\n",
        "    confm = confusion_matrix(y_test, predictions, labels=range(len(columns)))\n",
        "    df_cm = DataFrame(confm, index=columns, columns=columns)\n",
        "    pretty_plot_confusion_matrix(df_cm, fz=fz, cmap=cmap, figsize=figsize,\n",
        "                                 show_null_values=show_null_values,\n",
        "                                 pred_val_axis=pred_val_axis)\n",
        "\n",
        "def plot_confusion_matrix_with_sums_and_percentage(cm, class_names):\n",
        "    n_classes = cm.shape[0]\n",
        "\n",
        "    # Calculate sums\n",
        "    row_sums = cm.sum(axis=1)\n",
        "    col_sums = cm.sum(axis=0)\n",
        "    total_sum = np.sum(cm)\n",
        "    colors = [\"white\", \"lightBlue\"]  # Define the color range\n",
        "    cmap_name = \"custom_light\"\n",
        "    custom_light_cmap = LinearSegmentedColormap.from_list(cmap_name, colors)\n",
        "    # Expand the confusion matrix to include sums\n",
        "    cm_expanded = np.append(cm, row_sums[:, None], axis=1)  # Append row sums as new column\n",
        "    col_sums_expanded = np.append(col_sums, total_sum)  # Include total sum in column sums\n",
        "    cm_expanded = np.append(cm_expanded, col_sums_expanded[None, :], axis=0)  # Append column sums as new row\n",
        "\n",
        "    # Adjust class names for the expanded matrix\n",
        "    class_names_with_sums = class_names + [\"Sum\"]\n",
        "\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    sn.set(font_scale=1.2)\n",
        "\n",
        "    # Create a mask for non-diagonal cells to keep them white\n",
        "    mask = np.ones_like(cm_expanded, dtype=bool)\n",
        "    np.fill_diagonal(mask, False)\n",
        "    mask[-1, :] = True  # Keep last row white\n",
        "    mask[:, -1] = True  # Keep last column white\n",
        "\n",
        "    ax = sn.heatmap(cm_expanded, annot=True, fmt='d', square=True, cmap=custom_light_cmap,\n",
        "                    xticklabels=class_names_with_sums, yticklabels=class_names_with_sums,\n",
        "                    cbar=False, linewidths=.5, linecolor='white')\n",
        "    ax.set_facecolor('white')\n",
        "    ax.set_xlabel('Predicted')\n",
        "    ax.set_ylabel('Actual')\n",
        "    ax.set_title('Confusion Matrix with Sums and Percentage')\n",
        "\n",
        "    # Annotate percentages for the diagonal and sums\n",
        "    for i in range(n_classes + 1):\n",
        "        for j in range(n_classes + 1):\n",
        "            percentage_text = \"\"\n",
        "            if i < n_classes and j < n_classes and i == j:  # Diagonal cells\n",
        "                value_percentage = cm[i, j] / total_sum\n",
        "                color_opacity = np.clip(value_percentage, 0.1, 1)  # Ensure there's a minimum visibility\n",
        "                color_with_opacity = (0, 0, 1, color_opacity)  # RGB for blue with dynamic opacity\n",
        "\n",
        "                ax.add_patch(Rectangle((i, i), 1, 1, fill=True, color=color_with_opacity))\n",
        "\n",
        "                percentage = cm[i, j] / row_sums[i] if row_sums[i] > 0 else 0\n",
        "                # percentage_text = \"{:.1%}\".format(percentage)\n",
        "            elif i == n_classes and j < n_classes:  # Last row, excluding bottom right corner\n",
        "                percentage = (cm[j, j]) / col_sums[j] if col_sums[j] > 0 else 0\n",
        "                percentage_text = \"{:.1%}\".format(percentage)\n",
        "            elif j == n_classes and i < n_classes:  # Last column, excluding bottom right corner\n",
        "                percentage = (cm[i, i] ) / row_sums[i] if row_sums[i] > 0 else 0\n",
        "                percentage_text = \"{:.1%}\".format(percentage)\n",
        "            elif i== n_classes and j== n_classes:\n",
        "                percentage_text = \"No of\\nTest Images\"\n",
        "\n",
        "\n",
        "            if percentage_text:  # If percentage text is not empty, annotate the cell\n",
        "                ax.text(j + 0.5, i + 0.5, '\\n' + percentage_text, ha=\"center\", va=\"top\", color=\"black\", fontsize=\"x-small\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "cm = confusion_matrix(v_labels, v_preds)\n",
        "# Define class names\n",
        "columns = [\n",
        "    \"Face Brick\",\n",
        "    \"Timber\",\n",
        "    \"Steel Sheet\",\n",
        "    \"Plastered and Painted\",\n",
        "    \"Concrete and Glass\",\n",
        "    \"Glass\",\n",
        "    \"Fiber Cement Sheet\",\n",
        "    \"Concrete Panels\",\n",
        "    \"Unidentified\"\n",
        "]\n",
        "\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plot_confusion_matrix_with_sums_and_percentage(cm, class_names=columns)\n"
      ],
      "metadata": {
        "id": "Lho2o0nyoXOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFqA8w7djJwl"
      },
      "outputs": [],
      "source": [
        "# Performance Matrix\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "f1 = f1_score(v_labels, v_preds, average='macro')\n",
        "acc = accuracy_score(v_labels, v_preds)\n",
        "prec =  precision_score(v_labels, v_preds, average='macro', zero_division=0.0)\n",
        "rec = recall_score(v_labels, v_preds, average='macro')\n",
        "\n",
        "print(f\"f1 score: {f1:.3f}\")\n",
        "print(f\"accuracy: {acc:.3f}\")\n",
        "print(f\"precision: {prec:.3f}\")\n",
        "print(f\"recall: {rec:.3f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}